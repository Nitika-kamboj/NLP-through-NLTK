
## Tokeninzing words and Sentences with NLTK

Token - Each "entity" that is a part of whatever was split up based on rules. For examples, each word is a token when a sentence is "tokenized" into words. Each sentence can also be a token, if you tokenized the sentences out of a paragraph.

Tokenize are of two type:-

**1). word_tokenize :-** in this words of sentence are seperated . Even punctuation are also treated also seperated from the sentence like the words .There is also the seperation between the words like should'nt  into should and not.

**2).sent_tokenize :-** Return a sentence-tokenized copy of text
